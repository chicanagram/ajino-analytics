#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Fri Aug  2 20:54:14 2024

@author: charmainechia
"""
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from variables import data_folder, yvar_list_key, features_to_boost_dict, xvar_list_dict
from plot_utils import figure_folder, heatmap
from utils import sort_list
from feature_selection_utils import convert_fstxt_to_dict_list, get_fs_clusters, plot_fs_grid, FeatureSelectionModule

#%% Run Automated Feature Selection for selected parameters

fs_settings_dict = {
    '_knowledge-opt': {
        'fs_avg_weight': 0.5,
        'lasso_corr_scaling_power': 1,
        'lasso_distributed_scores_weight': 1,
        'nsrc_scaling_factor': 0.66,
        'knowledge_scaling_factor': 2,
        'corr_thres': 0.8,
        'num_features_to_select': 9,
        'max_num_highcorr_features': 2
        },
    '_model-opt': {
        'fs_avg_weight': 1,
        'lasso_corr_scaling_power': 1,
        'lasso_distributed_scores_weight': 0.5,
        'nsrc_scaling_factor': 0.33,
        'knowledge_scaling_factor': 0,
        'corr_thres': 0.8,
        'num_features_to_select': 8,
        'max_num_highcorr_features': 1
        },        
    'model-biased': {
        'fs_avg_weight': 1,
        'lasso_corr_scaling_power': 2,
        'lasso_distributed_scores_weight': 0,
        'nsrc_scaling_factor': 0.2,
        'knowledge_scaling_factor': 0.2,
        'corr_thres': 0.9,
        'num_features_to_select': 10,
        'max_num_highcorr_features': 2
        },
    'knowledge-biased': {
        'fs_avg_weight': 1,
        'lasso_corr_scaling_power': 1,
        'lasso_distributed_scores_weight': 1,
        'nsrc_scaling_factor': 0.5,
        'knowledge_scaling_factor': 2,
        'corr_thres': 0.85,
        'num_features_to_select': 8,
        'max_num_highcorr_features': 2
        },   
    '_ones': {
        'fs_avg_weight': 1,
        'lasso_corr_scaling_power': 1,
        'lasso_distributed_scores_weight': 1,
        'nsrc_scaling_factor': 1,
        'knowledge_scaling_factor': 1,
        'corr_thres': 0.85,
        'num_features_to_select': 8,
        'max_num_highcorr_features': 2
        },   
    }
#%%
fs_settings_to_test = ['_knowledge-opt'] #  ['model-biased', 'knowledge-biased'] #  
plot_scorecards = True
print_progress = True
feature_selections_bysetting = {}
for fs in fs_settings_to_test: 
    fs_settings = fs_settings_dict[fs]
    OptFeat = FeatureSelectionModule('X1Y0', yvar_list_key, features_to_boost_dict, 
                                     plot_scorecards=plot_scorecards, print_progress=print_progress, num_clusters=24)
    # select features
    features_selected_dict, xvars_unique_count_dict, corr_mat_selected, kfold_summary = OptFeat.run_feature_selection(fs_settings, fs)
    # calculate objective function based on selected features
    objfn = OptFeat.calculate_objective_function(fs_settings, fs, features_selected_dict, xvars_unique_count_dict, corr_mat_selected, kfold_summary)
    # update summary dict
    feature_selections_bysetting[fs] = {
        'features_selected': features_selected_dict,
        'model_eval': kfold_summary, 
        'num_unique_features_selected':len(xvars_unique_count_dict),
        'unique_features_selected': xvars_unique_count_dict}
    
print('\n', 'FINAL RESULTS SUMMARY:')
print(feature_selections_bysetting)
    
#%% Run GRIDSEARCH for Automated Feature Selection
from scipy import optimize

# get bounds of x0 to search
fs_param_names = ['fs_avg_weight', 'lasso_corr_scaling_power', 'lasso_distributed_scores_weight', 'nsrc_scaling_factor', 
                  'knowledge_scaling_factor', 'corr_thres', 'num_features_to_select', 'max_num_highcorr_features']
fs_params_dict_init = {
    'fs_avg_weight': 1,
    'lasso_corr_scaling_power': 2,
    'lasso_distributed_scores_weight': 1,
    'nsrc_scaling_factor': 0.2,
    'knowledge_scaling_factor': 1,
    'corr_thres': 0.85,
    'num_features_to_select': 10,
    'max_num_highcorr_features': 2    
    }
fs_params_ranges_dict = {
    'fs_avg_weight': slice(0.5,1.5,0.5),
    'lasso_corr_scaling_power': slice(1,4,1),
    'lasso_distributed_scores_weight': slice(0,1.5,0.5),
    'nsrc_scaling_factor': slice(0,1,0.33),
    'knowledge_scaling_factor': slice(0,2.5,0.5),
    'corr_thres': slice(0.8, 0.95,0.05),
    'num_features_to_select': slice(5, 10, 1),
    'max_num_highcorr_features': slice(1,4,1)
    }

fs_params_init = np.array([fs_params_dict_init[param] for param in fs_param_names])
fs_params_ranges = tuple([v for k,v in fs_params_ranges_dict.items()])

save_interval = 200
csv_fpath = f'{data_folder}feature_selection_GRIDSEARCH.csv'
OptFeat = FeatureSelectionModule('X1Y0', yvar_list_key, features_to_boost_dict, plot_scorecards=False, num_clusters=24, print_progress=False, save_interval=save_interval, csv_fpath=csv_fpath)
optres = optimize.brute(OptFeat.calculate_objective_function, fs_params_ranges, full_output=True, finish=None)
print('Best fs parameters:', optres[0])
print('Best results:', OptFeat.calculate_objective_function(optres[0]))


#%% Visualize gridsearch results
xvar_list_all = xvar_list_dict[1]
csv_fpath_avg = f'{data_folder}feature_selection_GRIDSEARCH.csv'
fs_res_avg = pd.read_csv(csv_fpath_avg, index_col='i')
print(len(fs_res_avg))
fs_res_avg = fs_res_avg.drop_duplicates(subset=['features_selected'])
fs_res_avg = fs_res_avg.sort_values(by='obj_fn', ascending=False)
print(len(fs_res_avg))

# filter out selections that decrease model performance too much
fs_res_avg = fs_res_avg[fs_res_avg['r2_increase']>-0.05]
print(len(fs_res_avg))
fs_txt_list = fs_res_avg['features_selected'].tolist()
fs_res_avg.to_csv(csv_fpath_avg[:-4]+'_deduplicated.csv')

# get overall feature selections and plot heatmap, and save as csv
fs_all_list, fs_idxs_all_list, fs_dict_list, fs_idxs_dict_list = convert_fstxt_to_dict_list(fs_txt_list, yvar_list_key, xvar_list_all)
fs_heatmap = plot_fs_grid(fs_idxs_all_list, xvar_list_all, nrows=6, figtitle='all feature selected')
fs_heatmap.to_csv(f'{data_folder}feature_selection_GRIDSEARCH_array.csv')

# get feature selections for each yvariable
csv_fpath_all = f'{data_folder}feature_selection_GRIDSEARCH_all.csv'
fs_res_all = pd.read_csv(csv_fpath_all, index_col='i')
ncalls_yvaridx = list(fs_res_all.index)
yvar_idx = [int(x[-1]) for x in ncalls_yvaridx]
fs_res_all.insert(0, 'yvar_idx', yvar_idx)

fs_yvar_dict = {}
fs_idxs_yvar_dict = {}
fs_df_dict = {}
fs_heatmap_avg_all = np.zeros((len(yvar_list_key), len(xvar_list_all)))
for i, yvar in enumerate(yvar_list_key):
    fs_res_yvar = fs_res_all[fs_res_all['yvar_idx']==i]
    fs_prefilt_list = [sort_list(fs_prefilt.split(', ')) for fs_prefilt in fs_res_yvar['features_selected'].tolist()]
    fs_res_yvar['features_selected'] = fs_prefilt_list
    print(yvar, len(fs_res_yvar))
    fs_res_yvar.drop_duplicates(subset=['features_selected'])
    fs_res_yvar = fs_res_yvar.sort_values(by='obj_fn', ascending=False)
    fs_res_yvar = fs_res_yvar[fs_res_yvar['r2_increase']>-0.02]
    fs_res_yvar.to_csv(csv_fpath_avg[:-4]+f'_deduplicated_{i}.csv')
    fs_df_dict[yvar] = fs_res_yvar
    print(yvar, len(fs_res_yvar))
    
    fs_yvar_dict[yvar] = fs_res_yvar['features_selected'].tolist()
    fs_idxs_yvar_dict[yvar] = []
    for fs_yvar in fs_yvar_dict[yvar]:
        fs_idxs_yvar = [xvar_list_all.index(xvar) for xvar in fs_yvar]
        fs_idxs_yvar_dict[yvar].append(fs_idxs_yvar)
    fs_heatmap_yvar = plot_fs_grid(fs_idxs_yvar_dict[yvar], xvar_list_all, nrows=10, figtitle=None) # f'{yvar}: features selected')
    fs_heatmap_yvar.to_csv(f'{data_folder}feature_selection_GRIDSEARCH_array_{i}.csv')
    
    # get averaged values
    fs_heatmap_avg_all[i, :] = np.mean(fs_heatmap_yvar, axis=1)

# plot heat map of averaged feature selections
fig, ax = plt.subplots(1,1, figsize=(20,4))
heatmap(fs_heatmap_avg_all[:, :-3], ax=ax, row_labels=yvar_list_key, col_labels=xvar_list_all[:-3], show_gridlines=False, fontsize=8)


# %% cluster feature sets selected through automated gridsearch

fs_df = pd.read_csv(f'{data_folder}feature_selection_GRIDSEARCH_deduplicated.csv')
fs_arr = pd.read_csv(f'{data_folder}feature_selection_GRIDSEARCH_array.csv', index_col=0).transpose()
kmeans_all, fs_kmeans_df_all = get_fs_clusters(fs_df, fs_arr, xvar_list_all, n_kmeans_clusters=5, random_state=0)
fs_clusters_avg_all = np.zeros((len(yvar_list_key), len(xvar_list_all)))

for i, yvar in enumerate(yvar_list_key):
    print('\n', yvar)
    fs_df_yvar = pd.read_csv(f'{data_folder}feature_selection_GRIDSEARCH_deduplicated_{i}.csv')
    wts = OptFeat.objfn_component_wts
    fs_df_yvar['obj_fn'] = wts['r2_increase']*fs_df_yvar['r2_increase'] + wts['frac_knowledge_features']*fs_df_yvar['frac_knowledge_features'] + wts['frac_allfeatures_selected']*fs_df_yvar['frac_allfeatures_selected'] + wts['frac_paired_features']*fs_df_yvar['frac_paired_features'] + wts['corr_avg_selected']*fs_df_yvar['corr_avg_selected'] 
    fs_arr_yvar = pd.read_csv(f'{data_folder}feature_selection_GRIDSEARCH_array_{i}.csv', index_col=0).transpose()
    kmeans_yvar, fs_kmeans_df_yvar = get_fs_clusters(fs_df_yvar, fs_arr_yvar, xvar_list_all, n_kmeans_clusters=5, random_state=0, print_top_fs=True)
    # get averaged values
    fs_clusters_avg_all[i, :] = np.mean(fs_kmeans_df_yvar, axis=0)  

# plot heat map of averaged feature selections
fig, ax = plt.subplots(1,1, figsize=(20,4))
heatmap(fs_clusters_avg_all[:, :-3], ax=ax, row_labels=yvar_list_key, col_labels=xvar_list_all[:-3], show_gridlines=False, fontsize=8)


#%% Run specific steps only for Automated Feature Selection ==> To get Justifications Table for AJINOMOTO

plot_scorecards = False
print_progress = False

# initialize feature selection module
fs_settings = fs_settings_dict['_ones']
OptFeat = FeatureSelectionModule('X1Y0', yvar_list_key, features_to_boost_dict, plot_scorecards=plot_scorecards, print_progress=print_progress, num_clusters=24)
OptFeat.get_settings(fs_settings, fs)
xvar_list_nutrients = OptFeat.xvar_list

# initialize df to register component scores
yvar_list_abbr = ['titer', 'man5', 'fuc', 'gal']
scorecard_component_names = [f'model_feature_importance_{yvar}' for yvar in yvar_list_abbr] + ['knowledge_importance_titer', 'knowledge_importance_glyco']
scorecard_components = pd.DataFrame(np.zeros((len(scorecard_component_names), len(xvar_list_nutrients))), index=scorecard_component_names, columns=xvar_list_nutrients)
# scorecard_component_names = [f'model_feature_importance_{yvar}' for yvar in yvar_list_abbr] + [f'correlation_NSRC_vs_{yvar}' for yvar in yvar_list_abbr] + ['knowledge_importance_titer', 'knowledge_importance_glyco']
# scorecard_components = pd.DataFrame(np.zeros((len(scorecard_component_names), len(xvar_list_nutrients))), index=scorecard_component_names, columns=xvar_list_nutrients)
scorecard_row_init = np.zeros((len(xvar_list_nutrients),))

# get model-based scores & NRSC boost scores
for i, (yvar, yvar_abbr) in enumerate(zip(yvar_list_key, yvar_list_abbr)):
    
    # get model scores
    # df = OptFeat.df_dict[yvar]
    # model_scores_yvar = OptFeat.add_feature_importance_scores(yvar, df, scorecard_row_init.copy())
    # model_scores_yvar_ranked = model_scores_yvar.argsort().argsort()
    # scorecard_components.loc[f'model_feature_importance_{yvar_abbr}', :] = model_scores_yvar_ranked
    model_scores_yvar = fs_heatmap_avg_all[i,:-3]
    scorecard_components.loc[f'model_feature_importance_{yvar_abbr}', :] = model_scores_yvar
    
    # # get NRSC scores
    # NSRC_scores_yvar = OptFeat.boost_with_NSRC_scores(yvar, df, scorecard_row_init.copy()+1)
    # NSRC_scores_yvar -= 1
    # NSRC_scores_yvar[NSRC_scores_yvar==1] = np.nan
    # scorecard_components.loc[f'correlation_NSRC_vs_{yvar_abbr}', :] = NSRC_scores_yvar
    
    # get domain knowledge scores
    knowledge_scores_yvar = OptFeat.boost_with_domain_knowledge(scorecard_row_init.copy()+1, yvar)
    knowledge_scores_yvar -= 1
    if yvar_abbr=='titer':
        scorecard_components.loc['knowledge_importance_titer', :] = knowledge_scores_yvar
    else:
        scorecard_components.loc['knowledge_importance_glyco', :] = knowledge_scores_yvar
 
    
 
from model_utils import plot_feature_importance_heatmap
arr, (fig,ax) = plot_feature_importance_heatmap(scorecard_components.copy(), xvar_list_nutrients, scorecard_component_names, logscale_cmap=False, scale_vals=True, annotate=None, get_clustermap=False, figtitle='Feature scores used for selection', savefig=None, return_fig_handle=True)

scorecard_components_annotations = np.zeros_like(scorecard_components.to_numpy())
scorecard_components_annotations[:] = np.nan
for row_idx in range(scorecard_components_annotations.shape[0]):
    scorecard_components_row = scorecard_components.iloc[row_idx, :].to_numpy()
    scorecard_components_row_nanmod = scorecard_components_row.copy()
    scorecard_components_row_nanmod[np.isnan(scorecard_components_row_nanmod)] = -1
    rankings = len(xvar_list_nutrients) - scorecard_components_row_nanmod.argsort().argsort()
    scorecard_components_annotations[row_idx,:] = rankings
    # annotate axis
    for col_idx, ranking in enumerate(rankings):
        if ~np.isnan(scorecard_components_row[col_idx]):
            ax.annotate(ranking, (col_idx-0.2, row_idx+0.2), fontsize=7, c='0.65')

plt.savefig(f'{figure_folder}FS_SCORECARD.png', bbox_inches='tight', dpi=400)
plt.show() 
