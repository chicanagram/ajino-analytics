#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Fri Aug  2 20:54:14 2024

@author: charmainechia
"""

import numpy as np
import pandas as pd
import matplotlib as mpl
from scipy.stats import rankdata
import matplotlib.pyplot as plt
from variables import yvar_list_key, xvar_list_dict
from model_utils import plot_feature_importance_heatmap
from plot_utils import figure_folder, heatmap
from get_datasets import data_folder, get_XYdata_for_featureset

def parse_model_type(f):
    if f.find('randomforest')>-1:
        model_type = 'randomforest'
    elif f.find('lasso')>-1:
        model_type = 'lasso'
    elif f.find('plsr')>-1:
        model_type = 'plsr'
    elif f.find('xgb')>-1:
        model_type = 'xgb'
    return model_type
                
def adapt_dfrow(dfrow_to_adapt, input_suffix, output_suffix, xvar_list_final, xvar_to_ignore=['DO', 'feed %', 'feed vol', 'pH']): 
    dfrow_final = np.zeros((len(xvar_list_final),))
    dfrow_final[:] = np.nan
    for i, xvar_base in enumerate(xvar_list_final): 
        for s in output_suffix:
            xvar_base = xvar_base.replace(s, input_suffix)
        if xvar_base in dfrow_to_adapt and xvar_base not in xvar_to_ignore:
            val = np.abs(dfrow_to_adapt[xvar_base])
            dfrow_final[i] = val
    return dfrow_final

def get_ranking_arr_across_row(val_arr):
    # get rankings by row
    ranking_arr = np.zeros_like(val_arr)
    ranking_arr[:] = np.nan
    for row_idx in range(val_arr.shape[0]):
        ranking_arr[row_idx,:] = val_arr.shape[1]+1-rankdata(val_arr[row_idx,:])
    # set nan elements to NaN
    ranking_arr[np.isnan(val_arr)] = np.nan
    return ranking_arr

def get_contents_of_brackets(string): 
    content_list = []
    string_to_search = string
    no_more_brackets = False
    while len(string_to_search)>3 and not no_more_brackets:
        startidx = string_to_search.find('(')
        if startidx > -1: 
            endidx = string_to_search[startidx:].find(')')
            content = string_to_search[startidx+1:startidx+endidx]
            content_list.append(content)
            string_to_search = string_to_search[startidx+endidx:]
        else: 
            no_more_brackets = True
    return content_list

#%% Aggregate feature selection rankings

# dataset parameters
base_featureset_idx = 1
base_dataset_name = f'X{base_featureset_idx}Y0'
dataset_suffix = ''
kfold_suffix = ''
xvar_list = xvar_list_dict[base_featureset_idx]

# display & thresholding
use_feature_rankings = False
apply_masking = False
feature_num_thres = 20
consumption_score_thres = 0.4
features_to_drop = ['DO', 'pH', 'feed vol', 'feed %'] # [] # 
features_to_annotate = ['Asn', 'Gln', 'Ser', 'Thr', 'Met', 'Cys', 'Pro', 'Gly', 'Asp', 'Glu', 'Riboflavin', 'Niacin', 'Pyridoxine', 'Folic acid', 'Ascorbic Acid', 'Tocopherol', 'Biotin', 'Mn', 'Ca', 'Mg', 'Zn', 'Cu', 'Uridine', 'Adenosine ', 'Cytidine ', 'Guanosine ', 'Putrescine ', 'Spermidine ', 'Spermine']
save_fig = True

# get feature order if sorted by correlations
sort_heatmap_by_clusters = False
cluster_df_sorted = pd.read_csv(f'{data_folder}features_by_cluster_corrdist.csv', index_col=0)
num_clusters_list = [24]
xvar_list_sorted_by_clusters = [xvar for xvar in cluster_df_sorted.columns.tolist() if xvar not in features_to_drop]

# initialize lists to store fileames and row labels
heatmap_rows_all = []
files_to_read_all = []
dataset_all = []

# mean absolute SHAP values
dataset_name = 'X1Y0'
model_type_list = ['randomforest', 'xgb']
heatmap_rows_all += [f'MC_{model_type}_SHAP' for model_type in model_type_list]
files_to_read = [f'feature_analysis_SHAP_{dataset_name}{dataset_suffix}_{model_type}.csv' for model_type in model_type_list]
files_to_read_all += files_to_read
dataset_all += [dataset_name] * len(files_to_read)

# feature selection methods
dataset_name = 'X1Y0'
model_type_list = ['randomforest'] 
feature_selection_method_list = ['rfe'] # ['rfe', 'sfs-forward']
files_to_read = [f'model_metrics_{feature_selection_method}_{dataset_name}{dataset_suffix}_{model_type}{kfold_suffix}.csv' for model_type in model_type_list for feature_selection_method in feature_selection_method_list]
heatmap_rows_all += [f'MC_{model_type}_{feature_selection_method}' for model_type in model_type_list for feature_selection_method in feature_selection_method_list]
files_to_read_all += files_to_read
dataset_all += [dataset_name] * len(files_to_read)

# feature importance scores
dataset_name = 'X1Y0'
model_type_list = ['randomforest', 'xgb', 'plsr', 'lasso']
heatmap_rows_all += [f'MC_{model_type}_coef_score' for model_type in model_type_list]
if use_feature_rankings:
    files_to_read = [f'model_feature_importance_{dataset_name}{dataset_suffix}{kfold_suffix}.csv']*len(model_type_list)
else:
    files_to_read = [f'model_feature_coef_{dataset_name}{dataset_suffix}{kfold_suffix}.csv']*len(model_type_list)
files_to_read_all += files_to_read
dataset_all += [dataset_name] * len(files_to_read)

# X-Y correlation scores
dataset_name = 'X1Y0'
heatmap_rows_all += [f'MC-vs-CQA_corr']
files_to_read = [f'{dataset_name}{dataset_suffix}{kfold_suffix}_correlation_matrix.csv']
files_to_read_all += files_to_read
dataset_all += [dataset_name] * len(files_to_read)

# feature importance scores
dataset_name = 'X4Y0'
model_type_list = ['lasso']
heatmap_rows_all += [f'NRSC_{model_type}_coef_score' for model_type in model_type_list]
# files_to_read = [f'model_feature_importance_{dataset_name}{dataset_suffix}{kfold_suffix}.csv']*len(model_type_list)
files_to_read = [f'model_feature_coef_{dataset_name}{dataset_suffix}{kfold_suffix}.csv']*len(model_type_list)
files_to_read_all += files_to_read
dataset_all += [dataset_name] * len(files_to_read)

# substrate consumption scores
dataset_name = 'X4Y0'
heatmap_rows_all += ['NSRC-vs-CQA_corr']
files_to_read = ['corr_cqa_nutrient_specific_rate_of_change.csv']
files_to_read_all += files_to_read
dataset_all += [dataset_name] * len(files_to_read)

# initialize dict for storing results
feature_metrics_by_yvar = {yvar: pd.DataFrame(columns=xvar_list, index=heatmap_rows_all) for yvar in yvar_list_key}

print(heatmap_rows_all)
print(files_to_read_all)


for f, row, dataset_name in zip(files_to_read_all, heatmap_rows_all, dataset_all):
    print(f,row, dataset_name)
    ##########################         
    # add results from SHAP #
    ########################## 
    if 'SHAP' in row:
        model_type = parse_model_type(row)
        for yvar in yvar_list_key: 
            print(f'***** {model_type}, {yvar} *****')
            df = pd.read_csv(f'{data_folder}{f}', index_col=0)
            # df = pd.read_csv(f'{data_folder}{f}', index_col=0)
            df_modeltype_yvar = df[(df.yvar==yvar) & (df.model_type==model_type)].iloc[0,2:].to_numpy()
            # use rankings of mean absolute shap values instead
            if use_feature_rankings:
                df_modeltype_yvar = rankdata(df_modeltype_yvar).astype(int)
            feature_metrics_by_yvar[yvar].loc[row, :] = df_modeltype_yvar
            
    ##############################################
    # add results from feature selection methods #
    ##############################################
    if any(x in row for x in ['rfe', 'sfs']):
        for yvar in yvar_list_key: 
            print(f'***** {yvar} *****')
            df = pd.read_csv(f'{data_folder}{f}', index_col=0)
            df_yvar = df[df.yvar==yvar]
        
            # sequential addition
            if f.find('sfs-forward')>1:
                xvar_list_ordered = df_yvar.xvar_to_add.tolist()
                xvar_list_ordered = xvar_list_ordered + [xvar for xvar in xvar_list if xvar not in xvar_list_ordered]
                xvar_list_ordered.reverse()
                    
            # sequential elimination
            elif f.find('sfs-backward')>-1 or f.find('rfe')>-1:
                xvar_list_ordered_ = df_yvar.xvar_to_drop.tolist()
                xvar_list_ordered = []
                for xvar in xvar_list_ordered_:
                    if xvar.find(', ')>-1:
                        xvar_sublist = xvar.split(', ')
                        xvar_sublist.reverse()
                    else:
                        xvar_sublist = [xvar]
                    xvar_list_ordered += xvar_sublist
            
            for i, xvar in enumerate(xvar_list_ordered):
                feature_metrics_by_yvar[yvar].loc[row, xvar] = i
                
    ###################################################           
    # add results from model fit feature coefficients #
    ###################################################   
    if 'coef' in row:
        model_type = parse_model_type(row)
        for yvar in yvar_list_key: 
            print(f'***** {model_type}, {yvar} *****')
            df = pd.read_csv(f'{data_folder}{f}', index_col=0)
            df_modeltype_yvar = df[(df.yvar==yvar) & (df.model_type==model_type)].iloc[0,2:].abs().to_numpy()
            if dataset_name!=base_dataset_name and dataset_name=='X4Y0':
                dfrow_to_adapt = pd.Series(df_modeltype_yvar, index=df.columns.to_numpy()[2:])
                dfrow_final = adapt_dfrow(dfrow_to_adapt, input_suffix='_NSRC', output_suffix=['_basal', '_feed'], xvar_list_final=xvar_list, xvar_to_ignore=['DO', 'feed %', 'feed vol', 'pH'])                
                feature_metrics_by_yvar[yvar].loc[row, :] = dfrow_final
            else:
                feature_metrics_by_yvar[yvar].loc[row, :] = df_modeltype_yvar
 
    #############################################    
    # add MC feature correlations with D14 CQAs #
    #############################################
    if 'corr' in row and 'MC' in row:
        MC_corr_df = pd.read_csv(f'{data_folder}{f}', index_col=0)
        for yvar in yvar_list_key:
            feature_metrics_by_yvar[yvar].loc[row, :] = MC_corr_df.loc[yvar,xvar_list]
    
    #############################################################     
    # add substrate consumption rate correlations with D14 CQAs #
    #############################################################   
    if 'corr' in row and 'NSRC' in row:
        nutrient_specific_rate_df = pd.read_csv(f'{data_folder}{f}', index_col=0)
        for yvar in yvar_list_key:
            dfrow_to_adapt = nutrient_specific_rate_df.loc[yvar.replace('_14',''), :]
            dfrow_final = adapt_dfrow(dfrow_to_adapt, input_suffix='', output_suffix=['_basal', '_feed'], xvar_list_final=xvar_list, xvar_to_ignore=['DO', 'feed %', 'feed vol', 'pH'])
            feature_metrics_by_yvar[yvar].loc[row, :] = dfrow_final
    
#############################
# process and plot heatmaps #
#############################
arr_dict = {}

for k, yvar in enumerate(yvar_list_key):
    df = feature_metrics_by_yvar[yvar].copy()
            
    # drop selected columns
    df_filt = df.drop([f for f in features_to_drop if f in df], axis=1)
    xvar_list_filt = [xvar for xvar in xvar_list if xvar not in features_to_drop]
    
    # apply mask --> set all values less than (p_init - NUM_FEATURE_THRES) to p_init - NUM_FEATURE_THRES (i.e. assume we can't distinguish between their importances)
    if apply_masking:
        thres_score = len(xvar_list)-feature_num_thres
        df_filt.iloc[1:,:][df_filt.iloc[1:,:]<=thres_score] = 0 # thres_score
        df_filt.iloc[:1,:][df_filt.iloc[:1,:]<=consumption_score_thres] = 0 # thres_score
                
    if sort_heatmap_by_clusters: 
        df_filt_sorted = df_filt[[xvar for xvar in xvar_list_sorted_by_clusters if xvar in df_filt]]
        xvar_list_filt_sorted = [xvar for xvar in xvar_list_sorted_by_clusters if xvar in df_filt]
    else: 
        df_filt_sorted = df_filt.copy()
        xvar_list_filt_sorted = xvar_list_filt.copy()
        
    arr, (fig,ax) = plot_feature_importance_heatmap(df_filt_sorted.copy(), xvar_list_filt_sorted, heatmap_rows_all, logscale_cmap=False, scale_vals=True, annotate=None, get_clustermap=False, figtitle=f'{yvar}: feature importances based on various selection methods', savefig=None, return_fig_handle=True)
    arr_df = pd.DataFrame(arr, columns=xvar_list_filt_sorted, index=heatmap_rows_all)
    arr_dict[yvar] = arr_df
    # save heatmap as CSV
    if use_feature_rankings: 
        arr_df.to_csv(f'{data_folder}feature_analysis_all_{k}_coefscores.png')
    else:
        arr_df.to_csv(f'{data_folder}feature_analysis_all_{k}_coefvals.png')
    
    # annotate with cluster 'labels'
    ncolors_in_palette = 10
    custom_palette = [plt.cm.tab10(i) for i in range(ncolors_in_palette)]
    row_offset = 0
    for num_clusters in num_clusters_list:
        custom_palette = custom_palette*int(np.ceil(num_clusters/ncolors_in_palette))
        cluster_labels = cluster_df_sorted.loc[num_clusters,:].to_numpy()
        for i, c in enumerate(cluster_labels[:len(xvar_list_filt_sorted)]):
            ax.scatter(np.array([i]), np.array([len(heatmap_rows_all)+row_offset]), s=20, color=custom_palette[int(c)])
        row_offset += 1
        
    # annotate with feature rankings
    ranking_arr = get_ranking_arr_across_row(df_filt_sorted.to_numpy().astype(float))
    for i in range(ranking_arr.shape[0]):
        for j in range(ranking_arr.shape[1]):
            val = ranking_arr[i,j]
            val = '' if np.isnan(val) else str(int(val))
            ax.annotate(val, (j-0.2,i+0.2), fontsize=6, c='0')
            
    # annotate glyco-relevant nutrients from the literature (ChatGPT)
    feature_idx_to_annotate = []
    for nutrient in features_to_annotate: 
        matching_idxs = [i for i, xvar in enumerate(xvar_list_filt_sorted) if nutrient in xvar]
        feature_idx_to_annotate += matching_idxs
    ax.scatter(np.array(feature_idx_to_annotate), np.array([-1]*len(feature_idx_to_annotate)), color='k', marker='v')
    
    if save_fig:
        if use_feature_rankings: 
            plt.savefig(f'{figure_folder}feature_analysis_all_{k}_coefscores.png', bbox_inches='tight', dpi=300)
        else: 
            plt.savefig(f'{figure_folder}feature_analysis_all_{k}_coefvals.png', bbox_inches='tight', dpi=300)
            
    plt.show()
    
#%% Plot averaged features as barplot
feature_selection_rows_to_average = [0,1,2,3]
num_clusters = 24
cluster_labels = cluster_df_sorted.loc[num_clusters,:].to_numpy()
ncolors_in_palette = 10
custom_palette = [plt.cm.tab10(i) for i in range(ncolors_in_palette)]
custom_palette = custom_palette*int(np.ceil(num_clusters/ncolors_in_palette))
color_list = [custom_palette[cluster_label] for cluster_label in cluster_labels]

for k, (yvar, arr) in enumerate(arr_dict.items()):
    # get average of first 6 feature selection method scores
    arr_avg = np.mean(arr.to_numpy()[feature_selection_rows_to_average,:], axis=0)
    xvar_list = arr.columns.tolist()
    
    # plot barplot
    fig, ax = plt.subplots(1,1, figsize=(10,5))
    xtickpos = np.arange(len(xvar_list))+1
    xticklabels = [str(idx) for idx in range(len(xvar_list))]
    width = 0.8
    ax.bar(xtickpos, arr_avg, width=width, color=color_list)
    ax.set_xticks(xtickpos, xvar_list, fontsize=7, rotation=90)
    ax.set_title(yvar, fontsize=20)
    ax.set_ylabel('feature importances', fontsize=16)
    plt.savefig(f'{figure_folder}feature_analysis_{k}_coefscores_AVG.png', bbox_inches='tight', dpi=300)
    plt.show()
        

#%% Plot averaged features across all 4 CQAs as heatmap
num_clusters_list = [24]
cluster_labels = cluster_df_sorted.loc[num_clusters,:].to_numpy()
ncolors_in_palette = 10
custom_palette = [plt.cm.tab10(i) for i in range(ncolors_in_palette)]
custom_palette = custom_palette*int(np.ceil(num_clusters/ncolors_in_palette))
color_list = [custom_palette[cluster_label] for cluster_label in cluster_labels]

df_avg_allcqas = pd.DataFrame(np.zeros((len(arr_dict), len(xvar_list_filt_sorted))), columns=xvar_list_filt_sorted, index=list(arr_dict.keys()))
for k, (yvar, arr) in enumerate(arr_dict.items()):
    # get average of first 6 feature selection method scores
    arr_avg = np.mean(arr.to_numpy()[:6,:], axis=0)
    df_avg_allcqas.loc[yvar,:] = arr_avg
    
arr_avg, (fig,ax) = plot_feature_importance_heatmap(df_avg_allcqas.copy(), df_avg_allcqas.columns.tolist(), list(df_avg_allcqas.index), logscale_cmap=False, scale_vals=True, annotate=None, get_clustermap=False, figtitle=f'Avg feature importances for all CQAs', savefig=None, return_fig_handle=True)

# annotate with cluster 'labels'
ncolors_in_palette = 10
custom_palette = [plt.cm.tab10(i) for i in range(ncolors_in_palette)]
row_offset = 0
for num_clusters in num_clusters_list:
    custom_palette = custom_palette*int(np.ceil(num_clusters/ncolors_in_palette))
    cluster_labels = cluster_df_sorted.loc[num_clusters,:].to_numpy()
    for i, c in enumerate(cluster_labels[:len(xvar_list_filt_sorted)]):
        ax.scatter(np.array([i]), np.array([df_avg_allcqas.shape[0]+row_offset]), s=20, color=custom_palette[int(c)])
    row_offset += 1
    
# save fig
plt.savefig(f'{figure_folder}feature_analysis_all_coefscores_AVG.png', bbox_inches='tight', dpi=300)
    
    
    